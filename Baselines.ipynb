{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T01:46:26.634845Z",
     "iopub.status.busy": "2021-12-02T01:46:26.634268Z",
     "iopub.status.idle": "2021-12-02T01:46:26.638445Z",
     "shell.execute_reply": "2021-12-02T01:46:26.637791Z",
     "shell.execute_reply.started": "2021-12-02T01:46:26.634806Z"
    }
   },
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Standards:** \n",
    "\n",
    "We use Python version 3.7.10 and scikit-learn packages for model training and prediction. Specifically, we use BernoulliNB, MultinomialNB, GaussianNB, svm, and KNeighborsClassifier packages from scikit-learn for our baseline models, and the MLPClassifier package for our experimental CNN model. Our accuracy measurements come from the scikit-learn accuracy_score and classification_report packages, and we find optimal parameters for our models using GridSearchCV.\n",
    "\n",
    "We also utilize the pandas and numpy libraries, as well as train_test_split and StandardScaler packages from the scikit-learn library, for data preprocessing and management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-04T15:18:33.569528Z",
     "iopub.status.busy": "2021-12-04T15:18:33.568687Z",
     "iopub.status.idle": "2021-12-04T15:18:35.840382Z",
     "shell.execute_reply": "2021-12-04T15:18:35.839049Z",
     "shell.execute_reply.started": "2021-12-04T15:18:33.569478Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB, GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import time\n",
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import \n",
    "\n",
    "Import data and take 10,000 samples from the data for model training and assessment, for time efficiency. The entire dataset has 35,887 rows; some of our models took over 9 hours to train on that much data. For this reason, we narrow the data by taking a sample in order to manage the amount of time spent on training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-04T15:29:02.440649Z",
     "iopub.status.busy": "2021-12-04T15:29:02.440322Z",
     "iopub.status.idle": "2021-12-04T15:29:05.421649Z",
     "shell.execute_reply": "2021-12-04T15:29:05.420944Z",
     "shell.execute_reply.started": "2021-12-04T15:29:02.440616Z"
    }
   },
   "outputs": [],
   "source": [
    "# import data\n",
    "# all_data = pd.read_csv('icml_face_data.csv')\n",
    "all_data = pd.read_csv('../input/facial-expression-recognition-challenge/icml_face_data.csv/icml_face_data.csv')\n",
    "# pd.read_csv('/kaggle/input/challenges-in-representation-learning-facial-expression-recognition-challenge/train.csv')\n",
    "# all_data = all_data[0:700] # just for dev... remove for actual training\n",
    "print(all_data.shape)\n",
    "all_data = all_data.sample(n=10000, random_state=1)\n",
    "\n",
    "accuracy = {}\n",
    "params = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-04T15:31:01.338896Z",
     "iopub.status.busy": "2021-12-04T15:31:01.338593Z",
     "iopub.status.idle": "2021-12-04T15:31:01.344031Z",
     "shell.execute_reply": "2021-12-04T15:31:01.342877Z",
     "shell.execute_reply.started": "2021-12-04T15:31:01.338866Z"
    }
   },
   "source": [
    "### Data Preprocessing\n",
    "\n",
    "After renaming the Usage and pixels columns for formatting, we define the function `pixels_to_arr` that convert a pandas Series of pixels to a numpy array of pixels, and apply it to the pixels column of our dataframe. This produces a one-dimensional array of 2,304 pixel values for each row of data.\n",
    "\n",
    "To make those arrays more usable, we then define the function `image_reshape` that reshapes each pixel array to a 48x48 matrix. Finally, we define the X and Y values we will feed into our models using the reshaped pixel matrices and their corresponding labels. We also create a `y_group` Series here that contains four labels, grouping the following emotions together: Angry/Sad, Fear/Surprise, Happy, and Neutral. Disgust is excluded because it has very little support (27 samples) in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-04T15:44:12.977616Z",
     "iopub.status.busy": "2021-12-04T15:44:12.976967Z",
     "iopub.status.idle": "2021-12-04T15:44:12.983460Z",
     "shell.execute_reply": "2021-12-04T15:44:12.982548Z",
     "shell.execute_reply.started": "2021-12-04T15:44:12.977579Z"
    }
   },
   "outputs": [],
   "source": [
    "all_data.rename({' Usage': 'Usage', ' pixels': 'pixels'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-04T15:44:12.985163Z",
     "iopub.status.busy": "2021-12-04T15:44:12.984936Z",
     "iopub.status.idle": "2021-12-04T15:44:21.511224Z",
     "shell.execute_reply": "2021-12-04T15:44:21.510193Z",
     "shell.execute_reply.started": "2021-12-04T15:44:12.985136Z"
    }
   },
   "outputs": [],
   "source": [
    "def pixels_to_arr(pixels):\n",
    "    array = np.array(pixels.split(),'float64')\n",
    "    return array\n",
    "\n",
    "all_data['pixels_arr'] = all_data['pixels'].apply(pixels_to_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-04T15:44:21.516654Z",
     "iopub.status.busy": "2021-12-04T15:44:21.516341Z",
     "iopub.status.idle": "2021-12-04T15:44:21.631325Z",
     "shell.execute_reply": "2021-12-04T15:44:21.630313Z",
     "shell.execute_reply.started": "2021-12-04T15:44:21.516619Z"
    }
   },
   "outputs": [],
   "source": [
    "def image_reshape(data):\n",
    "    image = np.reshape(data['pixels_arr'].to_list(),(data.shape[0],48,48,1))\n",
    "    return image\n",
    "\n",
    "X = image_reshape(all_data)\n",
    "y = all_data['emotion']\n",
    "y_group = all_data['emotion_group']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare train and test sets\n",
    "\n",
    "Here we create train and test sets using our 10,000-row dataframe. The training set has 8,000 rows and the testing set has 2,000 rows, and each contains 2,304 pixel values per row. The unraveled versions contain each value in its own column of the dataframe, and the standard versions contain the values as a single array. The unraveled format is used because it is better than a single array of pixel values for training models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-04T15:58:14.932267Z",
     "iopub.status.busy": "2021-12-04T15:58:14.931680Z",
     "iopub.status.idle": "2021-12-04T15:58:39.927698Z",
     "shell.execute_reply": "2021-12-04T15:58:39.926437Z",
     "shell.execute_reply.started": "2021-12-04T15:58:14.932214Z"
    }
   },
   "outputs": [],
   "source": [
    "x_unraveled = pd.DataFrame(list(map(np.ravel, all_data['pixels_arr'])))\n",
    "X_train_unrav, X_test_unrav, y_train_unrav, y_test_unrav = train_test_split(x_unraveled, y, test_size=0.2, random_state=12345)\n",
    "print(\"Pixels as columns\")\n",
    "print(\"Training data shape: \", X_train_unrav.shape)\n",
    "print(\"Test data shape\", X_test_unrav.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(all_data['pixels_arr'], y, test_size=0.2, random_state=12345)\n",
    "print(\"Pixels as Single array\")\n",
    "print(\"Training data shape: \", X_train.shape)\n",
    "print(\"Test data shape\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using additional emotion groupings (`y_group`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train_g, y_test_g = train_test_split(all_data['pixels_arr'], y_group, test_size=0.2, random_state=12345)\n",
    "X_train_unrav, X_test_unrav, y_train_unrav_g, y_test_unrav_g = train_test_split(x_unraveled, y_group, test_size=0.2, random_state=12345)\n",
    "X_train_im, X_test_im, y_train_im_g, y_test_im_g = train_test_split(X, y_group, test_size=0.2, random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Examination\n",
    "\n",
    "This is a preliminary examination of what is contained in our data. The first code block produces a bar chart showing the proportions of each labeled emotion within the 10,000-row dataframe. There is a notably higher proportion of \"happy\" samples than there are any other emotion, and a very low proportion of the samples are labeled \"disgust\". The rest of the labels comprise between 10-20% of the limited dataframe.\n",
    "\n",
    "The next block displays 5 samples with each label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-04T15:39:30.261988Z",
     "iopub.status.busy": "2021-12-04T15:39:30.261643Z",
     "iopub.status.idle": "2021-12-04T15:39:30.549468Z",
     "shell.execute_reply": "2021-12-04T15:39:30.548467Z",
     "shell.execute_reply.started": "2021-12-04T15:39:30.261958Z"
    }
   },
   "outputs": [],
   "source": [
    "emotion_prop = (all_data.emotion.value_counts() / len(all_data)).to_frame().sort_index(ascending=True)\n",
    "\n",
    "emotions = ['Angry','Disgust','Fear','Happy','Sad','Surprise','Neutral']\n",
    "palette = ['orchid', 'lightcoral', 'orange', 'gold', 'lightgreen', 'deepskyblue', 'cornflowerblue']\n",
    "\n",
    "plt.figure(figsize=[12,6])\n",
    "\n",
    "plt.bar(x=emotions, height=emotion_prop['emotion'], color=palette, edgecolor='black')\n",
    "    \n",
    "plt.xlabel('Emotion')\n",
    "plt.ylabel('Proportion')\n",
    "plt.title('Emotion Label Proportions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-04T15:47:25.139021Z",
     "iopub.status.busy": "2021-12-04T15:47:25.138667Z",
     "iopub.status.idle": "2021-12-04T15:47:26.812176Z",
     "shell.execute_reply": "2021-12-04T15:47:26.811497Z",
     "shell.execute_reply.started": "2021-12-04T15:47:25.138987Z"
    }
   },
   "outputs": [],
   "source": [
    "row = 0\n",
    "for emotion in list(range(7)):\n",
    "\n",
    "    all_emotion_images = all_data[all_data['emotion'] == emotion]\n",
    "    for i in range(5):\n",
    "        \n",
    "        img = all_emotion_images.iloc[i,].pixels_arr.reshape(48,48)\n",
    "        lab = emotions[emotion]\n",
    "        \n",
    "        plt.subplot(7,5,row+i+1)\n",
    "        plt.imshow(img, cmap='binary_r')\n",
    "        plt.axis('off')\n",
    "    plt.text(-600, 27, s = str(lab), fontsize=10)\n",
    "    row += 5\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Models\n",
    "\n",
    "We train and measure the prediction accuracy of 5 baseline models to later compare to our experimental model. Each model is trained on the unraveled training data, and tested on the unraveled testing data. We use GridSearchCV to perform a 5-fold cross-validated grid search for the optimal parameters with regard to accuracy for each model. The `accuracy` scoring parameter passed into the GridSearchCV function calls the `accuracy_score` function of scikit-learn, which returns the fraction of correctly classified samples in the test set. This is the value we use for each model's accuracy as a whole."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Nearest Neighbors Model\n",
    "\n",
    "The grid search for KNN model parameters includes all values of n between 1 and 19. It finds that the optimal number of neighbors for the 7-emotion model is 15; a model trained with these parameters is 28.15% accurate. For the 4-emotion model, the optimal number of neighbors is 2 and the model is 36.95% accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(algorithm='auto')\n",
    "param_grid = dict(n_neighbors=list(range(1, 16)))\n",
    "model_KNN = GridSearchCV(knn, param_grid, cv=5, scoring='accuracy',verbose=1)\n",
    "\n",
    "model_KNN.fit(X_train_unrav, y_train)\n",
    "y_pred_KNN = model_KNN.predict(X_test_unrav)\n",
    "\n",
    "print(model_KNN.best_params_)\n",
    "\n",
    "accuracy['KNN'] = accuracy_score(y_pred_KNN, y_test)\n",
    "params['KNN'] = model_KNN.best_params_\n",
    "print(f\"The model is {accuracy['KNN']*100:.2f}% accurate\")\n",
    "\n",
    "print('Classification Report:',classification_report(y_test,y_pred_KNN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-03T20:11:41.896173Z",
     "iopub.status.busy": "2021-12-03T20:11:41.895827Z",
     "iopub.status.idle": "2021-12-03T20:11:41.920835Z",
     "shell.execute_reply": "2021-12-03T20:11:41.919529Z",
     "shell.execute_reply.started": "2021-12-03T20:11:41.896137Z"
    }
   },
   "outputs": [],
   "source": [
    "print(model_KNN.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional groupings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(algorithm='auto')\n",
    "param_grid = dict(n_neighbors=list(range(1, 20)))\n",
    "model_KNN = GridSearchCV(knn, param_grid, cv=5, scoring='accuracy',verbose=1)\n",
    "\n",
    "model_KNN.fit(X_train_unrav, y_train_g)\n",
    "y_pred_KNN = model_KNN.predict(X_test_unrav)\n",
    "\n",
    "print(model_KNN.best_params_)\n",
    "\n",
    "accuracy['KNN_group'] = accuracy_score(y_pred_KNN, y_test_g)\n",
    "params['KNN_group'] = model_KNN.best_params_\n",
    "print(f\"The model is {accuracy['KNN_group']*100:.2f}% accurate\")\n",
    "\n",
    "print('Classification Report:',classification_report(y_test_g,y_pred_KNN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The grid search for SVM model parameters includes 5 possible values for the regularization parameter ('C'), four possible values for the kernel coefficient ('gamma'), and three possible kernel types. \n",
    "\n",
    "The best possible parameters from these options are a regularization paremeter of 0.1, a gamma value of 0.0001 and a linear kernel type. An SVC model from the scikit-learn SVM package trained with these parameters is 25% accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C':[0.01,0.1,1,10,100],'gamma':[0.0001,0.001,0.1,1],'kernel':['rbf','poly', 'linear']}\n",
    "svc = svm.SVC(probability=True)\n",
    "print(\"The training of the model is started, please wait for while as it may take few minutes to complete\")\n",
    "\n",
    "model_SVM = GridSearchCV(svc,param_grid)\n",
    "\n",
    "start = time.time()\n",
    "model_SVM.fit(X_train_unrav,y_train)\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Train time {end-start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The Model is trained well with the given images')\n",
    "print(model_SVM.best_params_)\n",
    "# {'C': 0.1, 'gamma': 0.0001, 'kernel': 'linear'}\n",
    "# The model is 25.00% accurate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_SVM = model_SVM.predict(X_test_unrav)\n",
    "accuracy['SVM'] = accuracy_score(y_pred_SVM, y_test)\n",
    "params['SVM'] = model_SVM.best_params_\n",
    "\n",
    "print(f\"The model is {accuracy['SVM']*100:.2f}% accurate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bernoulli Naive Bayes Model\n",
    "\n",
    "A grid search for Bernoulli Naive Bayes parameters searches for the best smoothing parameter ('alpha') from a list of 9 possibilities between 0 and 10. The model is given a binarization value of 0.1, meaning that any pixel values less than 0.1 are replaced by 0, and any above 0.1 are replaced by 1. \n",
    "\n",
    "In this configuration, the 7-emotion model has an optimal alpha value of 2.0. The trained 7-emotion model with this alpha value is 17.20% accurate. The 4-emotion model has an optimal alpha value of 1.0 which yields a 29.65% accurate model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-03T20:17:28.793535Z",
     "iopub.status.busy": "2021-12-03T20:17:28.792904Z",
     "iopub.status.idle": "2021-12-03T20:17:52.767903Z",
     "shell.execute_reply": "2021-12-03T20:17:52.766968Z",
     "shell.execute_reply.started": "2021-12-03T20:17:28.79348Z"
    }
   },
   "outputs": [],
   "source": [
    "alphas = {'alpha': [1.0e-10, 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 10.0]}\n",
    "\n",
    "bnb = BernoulliNB(binarize=0.1)\n",
    "model_BNB = GridSearchCV(bnb, alphas, scoring='accuracy')\n",
    "model_BNB.fit(X_train_unrav, y_train) \n",
    "\n",
    "y_pred_BNB = model_BNB.predict(X_test_unrav) \n",
    "accuracy['BNB'] = accuracy_score(y_pred_BNB,y_test)\n",
    "params['BNB'] = model_BNB.best_params_\n",
    "\n",
    "print(f\"The model is {accuracy['BNB']*100:.2f}% accurate\")\n",
    "\n",
    "print('Classification Report:',classification_report(y_test,y_pred_BNB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-03T20:20:39.761279Z",
     "iopub.status.busy": "2021-12-03T20:20:39.760929Z",
     "iopub.status.idle": "2021-12-03T20:20:39.767059Z",
     "shell.execute_reply": "2021-12-03T20:20:39.765889Z",
     "shell.execute_reply.started": "2021-12-03T20:20:39.761241Z"
    }
   },
   "outputs": [],
   "source": [
    "print(model_BNB.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional groupings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = {'alpha': [1.0e-10, 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 10.0]}\n",
    "\n",
    "bnb = BernoulliNB(binarize=0.1)\n",
    "model_BNB = GridSearchCV(bnb, alphas, scoring='accuracy')\n",
    "model_BNB.fit(X_train_unrav, y_train_g) \n",
    "\n",
    "y_pred_BNB = model_BNB.predict(X_test_unrav) \n",
    "accuracy['BNB_group'] = accuracy_score(y_pred_BNB,y_test_g)\n",
    "params['BNB_group'] = model_BNB.best_params_\n",
    "\n",
    "print(f\"The model is {accuracy['BNB_group']*100:.2f}% accurate\")\n",
    "\n",
    "print('Classification Report:',classification_report(y_test_g,y_pred_BNB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Naive Bayes Model\n",
    "\n",
    "A grid search for Multinomial Naive Bayes parameters also searches for the best smoothing parameter ('alpha') from the same list of 9 possibilities between 0 and 10 that was used for the Bernoulli Naive Bayes grid search. Data fed into the model is trinarized with thresholds of 0.25 and 0.75. This means that any pixel values less than 0.25 are replaced by 0, any between 0.25 and 0.75 are replaced by 1, and any above 0.75 are replaced by 2.\n",
    "\n",
    "In this configuration, the 7-emotion optimal alpha value is 10, and the resulting model is 22.65% accurate. The 4-emotion model has an optimal alpha value of 10, and is 33.70% accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-03T20:27:24.003803Z",
     "iopub.status.busy": "2021-12-03T20:27:24.003489Z",
     "iopub.status.idle": "2021-12-03T20:27:31.880881Z",
     "shell.execute_reply": "2021-12-03T20:27:31.87951Z",
     "shell.execute_reply.started": "2021-12-03T20:27:24.003771Z"
    }
   },
   "outputs": [],
   "source": [
    "# GRID SEARCH\n",
    "def trinarize(data, lower, upper):\n",
    "        trinarized_data = np.zeros(data.shape)\n",
    "        trinarized_data[(data <= lower)] = 0\n",
    "        trinarized_data[(data > lower)] = 1\n",
    "        trinarized_data[(data >= upper)] = 2\n",
    "        return trinarized_data\n",
    "\n",
    "alphas = {'alpha': [1.0e-10, 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 10.0]}\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "model_MNB = GridSearchCV(mnb, alphas, scoring='accuracy')\n",
    "model_MNB.fit(trinarize(X_train_unrav,0.25,0.75), y_train)\n",
    "y_pred_MNB = model_MNB.predict(trinarize(X_test_unrav,0.25,0.75))\n",
    "accuracy['MNB'] = accuracy_score(y_pred_MNB,y_test)\n",
    "params['MNB'] = model_MNB.best_params_\n",
    "\n",
    "print(f\"The Naive Bayes model is {accuracy['MNB']*100:.2f}% accurate\")\n",
    "\n",
    "print('Classification Report:',classification_report(y_test,y_pred_MNB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-03T20:27:31.996321Z",
     "iopub.status.busy": "2021-12-03T20:27:31.995092Z",
     "iopub.status.idle": "2021-12-03T20:27:32.003447Z",
     "shell.execute_reply": "2021-12-03T20:27:32.002673Z",
     "shell.execute_reply.started": "2021-12-03T20:27:31.996249Z"
    }
   },
   "outputs": [],
   "source": [
    "print(model_MNB.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional groupings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRID SEARCH\n",
    "def trinarize(data, lower, upper):\n",
    "        trinarized_data = np.zeros(data.shape)\n",
    "        trinarized_data[(data <= lower)] = 0\n",
    "        trinarized_data[(data > lower)] = 1\n",
    "        trinarized_data[(data >= upper)] = 2\n",
    "        return trinarized_data\n",
    "\n",
    "alphas = {'alpha': [1.0e-10, 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 10.0]}\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "model_MNB = GridSearchCV(mnb, alphas, scoring='accuracy')\n",
    "model_MNB.fit(trinarize(X_train_unrav,0.25,0.75), y_train_g)\n",
    "y_pred_MNB = model_MNB.predict(trinarize(X_test_unrav,0.25,0.75))\n",
    "accuracy['MNB_group'] = accuracy_score(y_pred_MNB,y_test_g)\n",
    "params['MNB_group'] = model_MNB.best_params_\n",
    "\n",
    "print(f\"The Naive Bayes model is {accuracy['MNB_group']*100:.2f}% accurate\")\n",
    "\n",
    "print('Classification Report:',classification_report(y_test_g,y_pred_MNB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes Model\n",
    "\n",
    "A grid search for Gaussian Naive Bayes parameters searches for the best smoothing variance, a portion of the largest variance of all the features, to add to each feature variance. This value is chosen from a collection of 100 possibilities in the log space between 0 and -9. \n",
    "\n",
    "The optimal smoothing variance for the 7-emotion model is ~0.0023, and the resulting model is 21.75% accurate. The optimal smoothing variance for the 4-emotion model is ~0.0035, and the resulting model is 36.15% accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-04T16:56:53.055819Z",
     "iopub.status.busy": "2021-12-04T16:56:53.055540Z",
     "iopub.status.idle": "2021-12-04T17:03:30.518441Z",
     "shell.execute_reply": "2021-12-04T17:03:30.517273Z",
     "shell.execute_reply.started": "2021-12-04T16:56:53.055790Z"
    }
   },
   "outputs": [],
   "source": [
    "#GRID SEARCH\n",
    "alphas = {'alpha': [1.0e-10, 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 10.0]}\n",
    "param_grid = {'var_smoothing': np.logspace(0,-9, num=100)}\n",
    "\n",
    "gnb2 = GaussianNB()\n",
    "model_GNB2 = GridSearchCV(gnb2, param_grid, scoring='accuracy')\n",
    "model_GNB2.fit(X_train_unrav, y_train)\n",
    "y_pred_GNB2 = model_GNB2.predict(X_test_unrav)\n",
    "accuracy['GNB'] = accuracy_score(y_pred_GNB2,y_test)\n",
    "params['GNB'] = model_GNB2.best_params_\n",
    "\n",
    "print('Classification Report:',classification_report(y_test,y_pred_GNB2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-04T17:03:30.520498Z",
     "iopub.status.busy": "2021-12-04T17:03:30.520230Z",
     "iopub.status.idle": "2021-12-04T17:03:30.526484Z",
     "shell.execute_reply": "2021-12-04T17:03:30.525058Z",
     "shell.execute_reply.started": "2021-12-04T17:03:30.520468Z"
    }
   },
   "outputs": [],
   "source": [
    "print(model_GNB2.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional groupings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GRID SEARCH\n",
    "alphas = {'alpha': [1.0e-10, 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 10.0]}\n",
    "param_grid = {'var_smoothing': np.logspace(0,-9, num=100)}\n",
    "\n",
    "gnb2 = GaussianNB()\n",
    "model_GNB2 = GridSearchCV(gnb2, param_grid, scoring='accuracy')\n",
    "model_GNB2.fit(X_train_unrav, y_train_g)\n",
    "y_pred_GNB2 = model_GNB2.predict(X_test_unrav)\n",
    "accuracy['GNB_group'] = accuracy_score(y_pred_GNB2,y_test_g)\n",
    "params['GNB_group'] = model_GNB2.best_params_\n",
    "\n",
    "print(f\"Gaussian Naive Bayes model with var_smoothing set to 0.1 had accuracy {accuracy['GNB_group']*100:.2f}%\")\n",
    "\n",
    "print('Classification Report:',classification_report(y_test_g,y_pred_GNB2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
